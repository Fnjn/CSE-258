{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import urllib\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "from sklearn import linear_model\n",
    "\n",
    "import string\n",
    "import math\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseData(fname):\n",
    "    for l in urllib.request.urlopen(fname):\n",
    "        yield eval(l)\n",
    "\n",
    "all_data = list(parseData(\"http://jmcauley.ucsd.edu/cse190/data/beer/beer_50000.json\"))\n",
    "\n",
    "data = all_data[:5000]\n",
    "corpus = [d['review/text'] for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('with', 'a'), 4587)\n",
      "(('in', 'the'), 2595)\n",
      "(('of', 'the'), 2245)\n",
      "(('is', 'a'), 2056)\n",
      "(('on', 'the'), 2033)\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "# 1\n",
    "##########################\n",
    "\n",
    "punctuation = set(string.punctuation)\n",
    "\n",
    "def puncFilter(text, rmPunc):\n",
    "    if rmPunc:\n",
    "        return ''.join([c for c in text.lower() if c not in punctuation])\n",
    "    else:\n",
    "        return ' '.join(re.findall(r\"\\w+|[^\\w\\s]\", text.lower()))\n",
    "\n",
    "def text2bigrams(text, rmPunc=True):\n",
    "    return nltk.bigrams(puncFilter(text, rmPunc).split())\n",
    "\n",
    "bigrams_cnt = Counter()\n",
    "\n",
    "for text in corpus:\n",
    "    bigrams_cnt += Counter(text2bigrams(text))\n",
    "    \n",
    "for i in bigrams_cnt.most_common(5):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.343317\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "# 2\n",
    "##########################\n",
    "\n",
    "def word_cnt_feature(top_grams, text_grams):\n",
    "    feat = [0] * len(top_grams)\n",
    "    for bi in text_grams:\n",
    "        try:\n",
    "            feat[top_grams.index(bi)] += 1\n",
    "        except:\n",
    "            pass\n",
    "    feat.append(1)\n",
    "    return feat\n",
    "\n",
    "\n",
    "def calMSE(X, y, lamda=1.0):\n",
    "    clf = linear_model.Ridge(lamda, fit_intercept=False)\n",
    "    clf.fit(X, y)\n",
    "    predictions = clf.predict(X)\n",
    "    return np.mean((y - predictions)**2)\n",
    "\n",
    "bigrams = [entry[0] for entry in bigrams_cnt.most_common(1000)]\n",
    "X = [word_cnt_feature(bigrams, text2bigrams(text)) for text in corpus]\n",
    "y = [d['review/overall'] for d in data]\n",
    "\n",
    "mse = calMSE(X, y)\n",
    "print('MSE: %f' % (mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# 3\n",
    "##########################\n",
    "\n",
    "def text2unigram(text, rmPunc=True):\n",
    "    return puncFilter(text, rmPunc).split()\n",
    "\n",
    "\n",
    "class NGramTFIDF:\n",
    "    def __init__(self, grams_list, cnvt, rmPunc=True):\n",
    "        self.IDF_D = {}\n",
    "        \n",
    "        self.cnvt = cnvt\n",
    "        self.rmPunc = rmPunc\n",
    "        self.grams_list = grams_list\n",
    "        \n",
    "    def calTF(self, word, gram):\n",
    "        cnt = Counter(gram)\n",
    "        try:\n",
    "            return cnt[word]\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "    def calIDF(self, word):\n",
    "        try:\n",
    "            idf = self.IDF_D[word]\n",
    "        except:\n",
    "            numer = len(self.textGrams)\n",
    "            denom = sum([1 if self.calTF(word, text) else 0 for text in self.textGrams])\n",
    "            denom = denom if denom !=0 else 1e-7 # avoid division by 0\n",
    "            idf = math.log10(numer / denom)\n",
    "            self.IDF_D[word] = idf\n",
    "        return idf\n",
    "\n",
    "    def calTF_IDF(self, word, textGram):\n",
    "        tf = self.calTF(word, textGram)\n",
    "        idf = self.calIDF(word)\n",
    "        return tf * idf\n",
    "    \n",
    "    def train(self, corpus):\n",
    "        self.TF_IDF = []\n",
    "        self.textGrams = [self.cnvt(text, self.rmPunc) for text in corpus]\n",
    "        \n",
    "        for i , text in enumerate(self.textGrams):\n",
    "            tf_idf = [self.calTF_IDF(gram, text) for gram in self.grams_list]\n",
    "            self.TF_IDF.append(tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"foam\" tf-idf score: 2.275737\n",
      "\"smell\" tf-idf score: 0.537902\n",
      "\"banana\" tf-idf score: 3.355561\n",
      "\"lactic\" tf-idf score: 5.841638\n",
      "\"tart\" tf-idf score: 1.806875\n"
     ]
    }
   ],
   "source": [
    "word_list = ['foam', 'smell', 'banana', 'lactic', 'tart']\n",
    "\n",
    "ngram_tf_idf = NGramTFIDF(word_list, text2unigram)\n",
    "ngram_tf_idf.train(corpus)\n",
    "\n",
    "for word, tf_idf in zip(word_list, ngram_tf_idf.TF_IDF[0]):\n",
    "    print('\"%s\" tf-idf score: %f' % (word, tf_idf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity: 0.106130\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "# 4\n",
    "##########################\n",
    "\n",
    "def cosine_similarity(x1, x2):\n",
    "    x1 = np.array(x1)\n",
    "    x2 = np.array(x2)\n",
    "    numer = x1.dot(x2)\n",
    "    denom = np.linalg.norm(x1) * np.linalg.norm(x2)\n",
    "    denom = denom if denom !=0 else 1e-7 # avoid division by 0\n",
    "    return numer / denom\n",
    "\n",
    "unigrams_cnt = Counter()\n",
    "\n",
    "for text in corpus:\n",
    "    unigrams_cnt += Counter(text2unigram(text))\n",
    "    \n",
    "unigrams = [entry[0] for entry in unigrams_cnt.most_common(1000)]\n",
    "\n",
    "ngram_tf_idf = NGramTFIDF(unigrams, text2unigram)\n",
    "ngram_tf_idf.train(corpus)\n",
    "\n",
    "tf_idf1 = ngram_tf_idf.TF_IDF[0]\n",
    "tf_idf2 = ngram_tf_idf.TF_IDF[1]\n",
    "\n",
    "cos_sim = cosine_similarity(tf_idf1, tf_idf2)\n",
    "print('Cosine similarity: %f' %(cos_sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# 5\n",
    "##########################\n",
    "\n",
    "cos_sim = {}\n",
    "for k, v in enumerate(ngram_tf_idf.TF_IDF):\n",
    "    cos_sim[k] = cosine_similarity(ngram_tf_idf.TF_IDF[0], v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beerID: 52211\n",
      "profileName: Frog's Hollow Double Pumpkin Ale\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Poured from a 22oz bottle to a Dogfish Head Snifter.\\t\\tColor: Slight hazy orange with an off white head.\\t\\tSmell: Cinnamon, banana, pumpkin and nutmeg.\\t\\tTaste: Alcohol, pumpkin, nutmeg, allspice and a hint of banana.\\t\\tMouthfeel: Medium carbonation, smooth, medium dryness on the palate.\\t\\tOverall: The smell is GREAT! The banana was a huge surprise for me. The taste had too much alcohol presence. Seemed to overpower the other flavors. Cheers!'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = sorted(cos_sim.items(), key=lambda x: x[1], reverse=True)[1][0]\n",
    "data[idx]\n",
    "\n",
    "print('beerID: %s' % data[idx]['beer/beerId'])\n",
    "print('profileName: %s' % data[idx]['beer/name'])\n",
    "data[idx]['review/text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.135513\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "# 6\n",
    "##########################\n",
    "\n",
    "X = ngram_tf_idf.TF_IDF\n",
    "y = [d['review/overall'] for d in data]\n",
    "\n",
    "mse = calMSE(X, y)\n",
    "print('MSE: %f' % (mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# 7\n",
    "##########################\n",
    "\n",
    "data = all_data\n",
    "corpus = [d['review/text'] for d in data]\n",
    "\n",
    "def split_data(X, Y, n_train, n_val, n_test, shuffle=False):\n",
    "    m = len(X)\n",
    "    n_val += n_train\n",
    "    n_test += n_val\n",
    "\n",
    "    if shuffle:\n",
    "        r = list(zip(X, Y))\n",
    "        random.shuffle(r)\n",
    "        X, Y = list(zip(*r))\n",
    "\n",
    "    return (X[:n_train], Y[:n_train]), (X[n_train:n_val], Y[n_train:n_val]), \\\n",
    "            (X[n_val:n_test], Y[n_val:n_test])\n",
    "\n",
    "# X = [feature(text) for text in corpus]\n",
    "y = [d['review/overall'] for d in data]\n",
    "\n",
    "trainData, valData, testData = split_data(corpus, y, 5000, 5000, 5000, shuffle=True)\n",
    "\n",
    "trainCorpus, trainY = trainData\n",
    "valCorpus, valY = valData\n",
    "testCorpus, testY = testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, top_grams, cnvt, rmPunc, use_tf_idf):\n",
    "        self.top_grams = top_grams\n",
    "        self.cnvt = cnvt\n",
    "        self.rmPunc = rmPunc\n",
    "        self.use_tf_idf = use_tf_idf\n",
    "        ngram_tf_idf = NGramTFIDF(top_grams, cnvt, rmPunc)\n",
    "        \n",
    "    def get_feature(self, corpus):\n",
    "        if self.use_tf_idf:\n",
    "            ngram_tf_idf.train(corpus)\n",
    "            self.TF_IDF = ngram_tf_idf.TF_IDF\n",
    "            return self.TF_IDF\n",
    "        \n",
    "        else:\n",
    "            return [word_cnt_feature(self.top_grams, self.cnvt(text, self.rmPunc)) \n",
    "                    for text in corpus]\n",
    "    \n",
    "    def train(self, X, y, lamda):\n",
    "        self.clf = linear_model.Ridge(lamda, fit_intercept=False)\n",
    "        self.clf.fit(X, y)\n",
    "        \n",
    "    def validation(self, X, y, lamdas):\n",
    "        best_mse = math.inf\n",
    "        best_lamda = None\n",
    "        best_clf = None\n",
    "        \n",
    "        for lamda in lamdas:\n",
    "            self.train(X, y, lamda)\n",
    "            mse = self.test(X, y)\n",
    "            \n",
    "            if mse < best_mse:\n",
    "                best_mse = mse\n",
    "                best_lamda = lamda\n",
    "                \n",
    "        self.best_lamda = best_lamda\n",
    "    \n",
    "    def test(self, X, y):\n",
    "        predictions = self.predict(X)\n",
    "        return np.mean((y - predictions)**2)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamdas = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "unigrams_cnt = Counter()\n",
    "bigrams_cnt = Counter()\n",
    "unigrams_cnt_ps = Counter()\n",
    "bigrams_cnt_ps = Counter()\n",
    "\n",
    "for text in trainCorpus:\n",
    "    unigrams_cnt += Counter(text2unigram(text))\n",
    "    bigrams_cnt += Counter(text2bigrams(text))\n",
    "    unigrams_cnt_ps += Counter(text2unigram(text, False))\n",
    "    bigrams_cnt_ps += Counter(text2bigrams(text, False))\n",
    "    \n",
    "unigrams = [entry[0] for entry in unigrams_cnt.most_common(1000)]\n",
    "bigrams = [entry[0] for entry in bigrams_cnt.most_common(1000)]\n",
    "unigrams_ps = [entry[0] for entry in unigrams_cnt_ps.most_common(1000)]\n",
    "bigrams_ps = [entry[0] for entry in bigrams_cnt_ps.most_common(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_time(startTime):\n",
    "    ts = time.time() - startTime\n",
    "    print('%dm, %ds' % (ts/60, ts%60))\n",
    "\n",
    "def pipeline(top_grams, cnvt, rmPunc, use_tf_idf):\n",
    "    startTime = time.time()\n",
    "\n",
    "    model = Model(top_grams, cnvt, rmPunc, use_tf_idf)\n",
    "    \n",
    "    trainX = model.get_feature(trainCorpus)\n",
    "    valX = model.get_feature(valCorpus)\n",
    "    testX = model.get_feature(testCorpus)\n",
    "\n",
    "    model.validation(valX, valY, lamdas)\n",
    "    model.train(trainX, trainY, model.best_lamda)\n",
    "    mse = model.test(testX, testY)\n",
    "    print_time(startTime)\n",
    "\n",
    "    return mse, model.best_lamda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2m, 30s\n",
      "2m, 29s\n",
      "2m, 32s\n",
      "2m, 26s\n",
      "0m, 12s\n",
      "0m, 51s\n",
      "0m, 12s\n",
      "0m, 55s\n"
     ]
    }
   ],
   "source": [
    "p1 = pipeline(unigrams, text2unigram, rmPunc=True, use_tf_idf=True)\n",
    "p2 = pipeline(bigrams, text2bigrams, rmPunc=True, use_tf_idf=True)\n",
    "\n",
    "p3 = pipeline(unigrams_ps, text2unigram, rmPunc=False, use_tf_idf=True)\n",
    "p4 = pipeline(bigrams_ps, text2bigrams, rmPunc=False, use_tf_idf=True)\n",
    "\n",
    "p5 = pipeline(unigrams, text2unigram, rmPunc=True, use_tf_idf=False)\n",
    "p6 = pipeline(bigrams, text2bigrams, rmPunc=True, use_tf_idf=False)\n",
    "\n",
    "p7 = pipeline(unigrams_ps, text2unigram, rmPunc=False, use_tf_idf=False)\n",
    "p8 = pipeline(bigrams_ps, text2bigrams, rmPunc=False, use_tf_idf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model desc                          mse      lambda  \n",
      "Unigrams, Remove, tfidf             2.02     0.01    \n",
      "Bigrams, Remove, tfidf              2.02     0.01    \n",
      "Unigrams, Perserve, tfidf           2.02     0.01    \n",
      "Bigrams, Perserve, tfidf            2.02     0.01    \n",
      "Unigrams, Remove, word counts       0.43     0.01    \n",
      "Bigrams, Remove, word counts        0.49     0.01    \n",
      "Unigrams, Perserve, word counts     0.43     0.01    \n",
      "Bigrams, Perserve, word counts      0.47     0.01    \n"
     ]
    }
   ],
   "source": [
    "res = [p1, p2, p3, p4, p5, p6, p7, p8]\n",
    "\n",
    "model_desc = ['Unigrams, Remove, tfidf',\n",
    "'Bigrams, Remove, tfidf',\n",
    "'Unigrams, Perserve, tfidf',\n",
    "'Bigrams, Perserve, tfidf',\n",
    "'Unigrams, Remove, word counts',\n",
    "'Bigrams, Remove, word counts',\n",
    "'Unigrams, Perserve, word counts',\n",
    "'Bigrams, Perserve, word counts']\n",
    "\n",
    "print (\"{:<35} {:<8} {:<8}\".format('model desc','mse','lambda'))\n",
    "for m, r in zip(model_desc, res):\n",
    "    print (\"{:<35} {:<8.2f} {:<8.2f}\".format(m, r[0], r[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
